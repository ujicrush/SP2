{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d52d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cvxpy as cp\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3a7af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Helper Functions: box uncertainty set & weighting factor ----------\n",
    "\n",
    "# 1. Construct the box-shaped uncertainty set Ξ (axis-aligned hyper-rectangle)\n",
    "def build_box_uncertainty(Z_all, qmin=0.01, qmax=0.99, eta=0.02):\n",
    "    \"\"\"return [ell, upp] in each dimension of Z_all\"\"\"\n",
    "    low  = np.quantile(Z_all, qmin, axis=0)\n",
    "    high = np.quantile(Z_all, qmax, axis=0)\n",
    "    span = high - low\n",
    "    ell  = low  - eta * span\n",
    "    upp  = high + eta * span\n",
    "    # Avoid zero-width intervals\n",
    "    upp = np.maximum(upp, ell + 1e-10)\n",
    "    return ell, upp\n",
    "\n",
    "def build_box_conic_from_bounds(ell, upp, n):\n",
    "    \"\"\"\n",
    "    Rewrite the box uncertainty set  Ξ = { (x,y): ell <= (x,y) <= upp }\n",
    "    into the form C1 x + c2 y <= d   (C is the nonnegative orthant cone), for direct use of Corollary 3.3.\n",
    "    Return C1 (m*n), c2 (m,), d (m,), where m = 2*(n+1)\n",
    "    where n = dim(x), y is a scalar\n",
    "    \"\"\"\n",
    "    m = 2*(n+1)\n",
    "    C1 = np.zeros((m, n))\n",
    "    c2 = np.zeros(m)\n",
    "    d  = np.zeros(m)\n",
    "\n",
    "    row = 0\n",
    "    # upper bound： x_j <= upp_j\n",
    "    for j in range(n):\n",
    "        C1[row, j] = 1.0\n",
    "        d[row] = upp[j]\n",
    "        row += 1\n",
    "    # lower bound： -x_j <= -ell_j\n",
    "    for j in range(n):\n",
    "        C1[row, j] = -1.0\n",
    "        d[row] = -ell[j]\n",
    "        row += 1\n",
    "    # upper bound for y： y <= upp_y\n",
    "    c2[row] = 1.0\n",
    "    d[row] = upp[n]\n",
    "    row += 1\n",
    "    # lower bound for y： -y <= -ell_y\n",
    "    c2[row] = -1.0\n",
    "    d[row] = -ell[n]\n",
    "    row += 1\n",
    "\n",
    "    assert row == m\n",
    "    return C1, c2, d\n",
    "\n",
    "# 2a. Compute time-dependent sample weights (exponential forgetting)\n",
    "def time_weights_from_indices(time_idx, now_t, decay):\n",
    "    raw = decay ** (now_t - time_idx)\n",
    "    pi = raw / raw.sum()\n",
    "    return pi\n",
    "\n",
    "# 2b. Optimal weights according to Proposition 2 (for p = 1)\n",
    "def optimal_weights_prop2(T, eps_over_rho):\n",
    "    \"\"\"\n",
    "    Proposition 2 optimal weights for p = 1:\n",
    "    - T = history length\n",
    "    - eps_over_rho = ε/ρ in the paper, where eps in our code is ambuiguity radius, rho is the wasserstein distance between Pt and Pt+1\n",
    "    Return weights w of length T\n",
    "    \"\"\"\n",
    "\n",
    "    # s = floor(eps / rho)\n",
    "    s = int(np.floor(eps_over_rho))\n",
    "    s = max(1, min(s, T))  # truncate to [1, T]\n",
    "    \n",
    "    w = np.zeros(T)\n",
    "    denom = s * (2 * eps_over_rho - s - 1)\n",
    "    \n",
    "    for t in range(T - s, T):\n",
    "        # t runs from T-s to T-1  (0-index)\n",
    "        w[t] = 2 * ((eps_over_rho) + (t+1) - T - 1) / denom\n",
    "\n",
    "    return w\n",
    "\n",
    "# 3. DRO ε-insensitive SVR\n",
    "# ---------- Core：DRO-SVR following Corollary 3.3 ----------\n",
    "def solve_dro_svr_cor33(X, y, C1, c2, d, pi, epsilon=1.0, rho=0.5, use_mosek=True):\n",
    "    \"\"\"\n",
    "    Corollary 3.3 (Support Vector Regression):\n",
    "      min   λ ρ + sum_i π_i s_i\n",
    "      s.t.  y_i - <w,x_i> - ε + <p_i^+, d - C1 x_i - c2 y_i> <= s_i\n",
    "            <w,x_i> - y_i - ε + <p_i^-, d - C1 x_i - c2 y_i> <= s_i\n",
    "            || ( C1^T p_i^+ + w ,  c2^T p_i^+ - 1 ) ||_* <= λ\n",
    "            || ( C1^T p_i^- - w ,  c2^T p_i^- + 1 ) ||_* <= λ\n",
    "            p_i^+, p_i^- >= 0,  s_i >= 0\n",
    "    \"\"\"\n",
    "    N, n = X.shape\n",
    "    m = C1.shape[0]  # number of constraints (2*(n+1))\n",
    "\n",
    "    w   = cp.Variable(n)\n",
    "    lam = cp.Variable(nonneg=True)\n",
    "    s   = cp.Variable(N, nonneg=True)\n",
    "\n",
    "    constraints = []\n",
    "\n",
    "    # pre-calculate (d - C1 x_i - c2 y_i) for each sample\n",
    "    D_minus_Axi_cy = (d[None, :] - X @ C1.T - np.outer(y, c2))  # (N,m)\n",
    "\n",
    "    for i in range(N):\n",
    "        p_plus_i  = cp.Variable(m, nonneg=True)\n",
    "        p_minus_i = cp.Variable(m, nonneg=True)\n",
    "\n",
    "        # y_i - <w,x_i> - ε + <p_i^+, ...> <= s_i\n",
    "        lhs1_i = (y[i] - X[i] @ w - epsilon + p_plus_i @ D_minus_Axi_cy[i, :])\n",
    "        constraints += [lhs1_i <= s[i]]\n",
    "\n",
    "        # <w,x_i> - y_i - ε + <p_i^-, ...> <= s_i\n",
    "        lhs2_i = (X[i] @ w - y[i] - epsilon + p_minus_i @ D_minus_Axi_cy[i, :])\n",
    "        constraints += [lhs2_i <= s[i]]\n",
    "\n",
    "        # || ( C1^T p_i^+ + w ,  c2^T p_i^+ - 1 ) ||_2 <= λ\n",
    "        # || ( C1^T p_i^- - w ,  c2^T p_i^- + 1 ) ||_2 <= λ\n",
    "        vec_minus = cp.hstack([C1.T @ p_minus_i - w,  c2 @ p_minus_i + 1.0])\n",
    "        vec_plus = cp.hstack([C1.T @ p_plus_i + w,  c2 @ p_plus_i - 1.0])\n",
    "\n",
    "        constraints += [\n",
    "            cp.norm(vec_plus,  'inf') <= lam,\n",
    "            cp.norm(vec_minus, 'inf') <= lam\n",
    "        ]\n",
    "\n",
    "    # objective：λ ρ + sum_i π_i s_i\n",
    "    pi_param = cp.Parameter(N, nonneg=True, value=np.asarray(pi, float))\n",
    "    obj = cp.Minimize(lam * rho + pi_param @ s)\n",
    "\n",
    "    prob = cp.Problem(obj, constraints)\n",
    "    try:\n",
    "        prob.solve(solver=cp.MOSEK if use_mosek else cp.ECOS, verbose=False)\n",
    "    except cp.SolverError:\n",
    "        prob.solve(solver=cp.ECOS, verbose=False)\n",
    "\n",
    "    return w.value, prob.status\n",
    "\n",
    "# 4. Empirical ε-insensitive SVR (no regularization, time-weighted)\n",
    "def solve_empirical_svr_noreg(X, y, epsilon=1.0, sample_weights=None, use_mosek=True):\n",
    "    N, n = X.shape\n",
    "    w = cp.Variable(n)\n",
    "    resid = y - X @ w\n",
    "    loss  = cp.pos(cp.abs(resid) - epsilon)  # max(0, |r|-ε)\n",
    "\n",
    "    if sample_weights is None:\n",
    "        obj = cp.Minimize(cp.sum(loss) / N)\n",
    "    else:\n",
    "        sw = cp.Parameter(N, nonneg=True, value=np.asarray(sample_weights, float))\n",
    "        weighted_loss = cp.sum(cp.multiply(sw, loss))\n",
    "        obj = cp.Minimize(weighted_loss)\n",
    "\n",
    "    prob = cp.Problem(obj)\n",
    "    try:\n",
    "        prob.solve(solver=cp.MOSEK if use_mosek else cp.ECOS, verbose=False)\n",
    "    except cp.SolverError:\n",
    "        prob.solve(solver=cp.ECOS, verbose=False)\n",
    "    return w.value, prob.status\n",
    "\n",
    "# 5. ε-insensitive loss\n",
    "def eps_ins_loss(y_true, y_pred, eps):\n",
    "    return np.maximum(0, np.abs(y_true - y_pred) - eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10cef43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_real_excel_dataset(path):\n",
    "    df = pd.read_excel(path)\n",
    "\n",
    "    if 'No' in df.columns:\n",
    "        df = df.drop(columns=['No'])\n",
    "\n",
    "    data = df.values\n",
    "    X = data[:, :-1].astype(float)\n",
    "    y = data[:, -1].astype(float)\n",
    "\n",
    "    X1 = X[:, 0]\n",
    "    year = np.floor(X1).astype(int)\n",
    "    month_float = np.round((X1 - year) * 12).astype(int)\n",
    "    month = np.clip(month_float, 1, 12)\n",
    "\n",
    "    year_min = year.min()\n",
    "    time_index = (year - year_min) * 12 + (month - 1)\n",
    "\n",
    "    X[:, 0] = time_index\n",
    "\n",
    "    y_m2 = y / 3.3\n",
    "\n",
    "    return X, y_m2, time_index\n",
    "\n",
    "X_raw, y_real, time_index_all = load_real_excel_dataset(\"Real estate valuation data set.xlsx\")\n",
    "\n",
    "def add_pure_correlation_drift(X, y, time_index, feature_id, strength=0.01):\n",
    "    t = (time_index - time_index.min()) / time_index.max()\n",
    "\n",
    "    y_mean = y.mean()\n",
    "    y_std = y.std()\n",
    "\n",
    "    y_norm = (y - y_mean) / y_std\n",
    "\n",
    "    drift_term = strength * t * (\n",
    "        (X[:, feature_id] - X[:, feature_id].mean()) / X[:, feature_id].std()\n",
    "    )\n",
    "\n",
    "    y_new = y_norm + drift_term\n",
    "    return y_new * y_std + y_mean\n",
    "\n",
    "y_drift = add_pure_correlation_drift(\n",
    "    X_raw,\n",
    "    y_real,\n",
    "    time_index_all,\n",
    "    feature_id=2,\n",
    "    strength=0.7\n",
    ")\n",
    "\n",
    "y_real = y_drift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d9c2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "order = np.argsort(time_index_all)\n",
    "\n",
    "time_sorted = time_index_all[order]\n",
    "X_sorted_full = X_raw[order]\n",
    "y_sorted = y_real[order]\n",
    "\n",
    "X_features_sorted = X_sorted_full[:, 1:]\n",
    "\n",
    "all_times = np.unique(time_sorted.astype(int))\n",
    "T_total = len(all_times)\n",
    "\n",
    "# ================================\n",
    "# 0. Hyperparameter grid\n",
    "# ================================\n",
    "epsilon = 1\n",
    "\n",
    "time_ratios = [0.6, 0.7, 0.8, 0.9]\n",
    "rho_list    = np.logspace(-4, 1, num=10)\n",
    "decay_list  = [0.65, 0.75, 0.85, 0.95]\n",
    "\n",
    "results = {\n",
    "    \"ratio\": [],\n",
    "    \"SAA\": [],\n",
    "    \"W-SAA\": [],\n",
    "    \"WDRO\": [],\n",
    "    \"Prop2\": []\n",
    "}\n",
    "\n",
    "# ================================\n",
    "# Main loop over training ratios\n",
    "# ================================\n",
    "for ratio in time_ratios:\n",
    "\n",
    "    # ------------------------------------------------\n",
    "    # 1. Outer split: Train+Val / Test by MONTH\n",
    "    # ------------------------------------------------\n",
    "    T_cut = int(ratio * T_total)\n",
    "\n",
    "    trainval_times = all_times[:T_cut]\n",
    "    test_times     = all_times[T_cut:]\n",
    "\n",
    "    trainval_mask = np.isin(time_sorted.astype(int), trainval_times)\n",
    "    test_mask     = np.isin(time_sorted.astype(int), test_times)\n",
    "\n",
    "    X_trainval = X_features_sorted[trainval_mask]\n",
    "    y_trainval = y_sorted[trainval_mask]\n",
    "\n",
    "    X_test = X_features_sorted[test_mask]\n",
    "    y_test = y_sorted[test_mask]\n",
    "\n",
    "    print(f\"\\n=== Time ratio {ratio:.1f} ===\")\n",
    "    print(\"Train+Val samples:\", X_trainval.shape[0])\n",
    "    print(\"Test samples     :\", X_test.shape[0])\n",
    "\n",
    "    # ------------------------------------------------\n",
    "    # 2. Inner split: Train / Val  (NO test leakage)\n",
    "    # ------------------------------------------------\n",
    "    inner_ratio = 0.8\n",
    "    n_train = int(inner_ratio * X_trainval.shape[0])\n",
    "\n",
    "    X_train = X_trainval[:n_train]\n",
    "    y_train = y_trainval[:n_train]\n",
    "\n",
    "    X_val = X_trainval[n_train:]\n",
    "    y_val = y_trainval[n_train:]\n",
    "\n",
    "    print(\"  Train samples:\", X_train.shape[0])\n",
    "    print(\"  Val   samples:\", X_val.shape[0])\n",
    "\n",
    "    # ------------------------------------------------\n",
    "    # 3. Build MONTH → SAMPLE index ONLY on TRAIN\n",
    "    # ------------------------------------------------\n",
    "    time_train = time_sorted[trainval_mask][:n_train].astype(int)\n",
    "\n",
    "    unique_times, inv_idx = np.unique(time_train, return_inverse=True)\n",
    "    T_time = len(unique_times)\n",
    "    counts = np.bincount(inv_idx)   # samples per month\n",
    "\n",
    "    # ------------------------------------------------\n",
    "    # 4. Build Box uncertainty set (TRAIN only)\n",
    "    # ------------------------------------------------\n",
    "    Z_train = np.hstack([X_train, y_train[:, None]])\n",
    "    ell, upp = build_box_uncertainty(Z_train, qmin=0.01, qmax=0.99, eta=0.02)\n",
    "    C1, c2, d = build_box_conic_from_bounds(ell, upp, X_train.shape[1])\n",
    "\n",
    "    # ============================================================\n",
    "    # 5. SAA  (no hyperparameter tuning)\n",
    "    # ============================================================\n",
    "    w_saa, _ = solve_empirical_svr_noreg(X_train, y_train, epsilon=epsilon)\n",
    "    y_val_pred = X_val @ w_saa\n",
    "    val_loss_saa = eps_ins_loss(y_val, y_val_pred, epsilon).mean()\n",
    "\n",
    "    print(\"  [SAA]   val eps-loss:\", val_loss_saa)\n",
    "\n",
    "    # ============================================================\n",
    "    # 6. W-SAA  (tune decay on VAL, batch → sample weights)\n",
    "    # ============================================================\n",
    "    best_wsaa_loss = np.inf\n",
    "    best_wsaa_decay = None\n",
    "\n",
    "    for decay in decay_list:\n",
    "        time_idx_month = np.arange(T_time)\n",
    "\n",
    "        pi_time_wsaa = time_weights_from_indices(\n",
    "            time_idx_month,\n",
    "            now_t=T_time - 1,\n",
    "            decay=decay\n",
    "        )\n",
    "\n",
    "        pi_wsaa_samples = pi_time_wsaa[inv_idx] / counts[inv_idx]\n",
    "        pi_wsaa_samples = pi_wsaa_samples / pi_wsaa_samples.sum()\n",
    "\n",
    "        w_wsaa, _ = solve_empirical_svr_noreg(\n",
    "            X_train, y_train,\n",
    "            epsilon=epsilon,\n",
    "            sample_weights=pi_wsaa_samples\n",
    "        )\n",
    "\n",
    "        y_val_pred = X_val @ w_wsaa\n",
    "        val_loss = eps_ins_loss(y_val, y_val_pred, epsilon).mean()\n",
    "\n",
    "        if val_loss < best_wsaa_loss:\n",
    "            best_wsaa_loss = val_loss\n",
    "            best_wsaa_decay = decay\n",
    "\n",
    "    print(\"  [W-SAA] best val eps-loss:\", best_wsaa_loss,\n",
    "          \"| best decay =\", best_wsaa_decay)\n",
    "\n",
    "    # ============================================================\n",
    "    # 7. WDRO  (tune decay + rho on VAL)\n",
    "    # ============================================================\n",
    "    best_wdro_loss = np.inf\n",
    "    best_wdro_decay = None\n",
    "    best_wdro_rho = None\n",
    "\n",
    "    for decay in decay_list:\n",
    "        time_idx_month = np.arange(T_time)\n",
    "\n",
    "        pi_time_wdro = time_weights_from_indices(\n",
    "            time_idx_month,\n",
    "            now_t=T_time - 1,\n",
    "            decay=decay\n",
    "        )\n",
    "\n",
    "        pi_wdro_samples = pi_time_wdro[inv_idx] / counts[inv_idx]\n",
    "        pi_wdro_samples = pi_wdro_samples / pi_wdro_samples.sum()\n",
    "\n",
    "        for rho in rho_list:\n",
    "            w_wdro, _ = solve_dro_svr_cor33(\n",
    "                X_train, y_train,\n",
    "                C1, c2, d,\n",
    "                pi_wdro_samples,\n",
    "                epsilon=epsilon,\n",
    "                rho=rho\n",
    "            )\n",
    "\n",
    "            y_val_pred = X_val @ w_wdro\n",
    "            val_loss = eps_ins_loss(y_val, y_val_pred, epsilon).mean()\n",
    "\n",
    "            if val_loss < best_wdro_loss:\n",
    "                best_wdro_loss = val_loss\n",
    "                best_wdro_decay = decay\n",
    "                best_wdro_rho = rho\n",
    "\n",
    "    print(\"  [WDRO]  best val eps-loss:\", best_wdro_loss,\n",
    "          \"| best decay =\", best_wdro_decay,\n",
    "          \"| best rho =\", best_wdro_rho)\n",
    "\n",
    "    # ============================================================\n",
    "    # 8. Prop2-DRO  (tune rho + eps/rho on VAL)\n",
    "    # ============================================================\n",
    "    eps_over_rho_list = np.linspace(1.1, T_time, 6)\n",
    "\n",
    "    best_prop2_loss = np.inf\n",
    "    best_prop2_rho = None\n",
    "    best_prop2_epsrho = None\n",
    "\n",
    "    for rho in rho_list:\n",
    "        for eps_over_rho in eps_over_rho_list:\n",
    "\n",
    "            pi_time_prop2 = optimal_weights_prop2(T_time, eps_over_rho)\n",
    "            pi_time_prop2 = pi_time_prop2 / pi_time_prop2.sum()\n",
    "\n",
    "            pi_prop2_samples = pi_time_prop2[inv_idx] / counts[inv_idx]\n",
    "            pi_prop2_samples = pi_prop2_samples / pi_prop2_samples.sum()\n",
    "\n",
    "            w_prop2, _ = solve_dro_svr_cor33(\n",
    "                X_train, y_train,\n",
    "                C1, c2, d,\n",
    "                pi_prop2_samples,\n",
    "                epsilon=epsilon,\n",
    "                rho=rho\n",
    "            )\n",
    "\n",
    "            y_val_pred = X_val @ w_prop2\n",
    "            val_loss = eps_ins_loss(y_val, y_val_pred, epsilon).mean()\n",
    "\n",
    "            if val_loss < best_prop2_loss:\n",
    "                best_prop2_loss = val_loss\n",
    "                best_prop2_rho = rho\n",
    "                best_prop2_epsrho = eps_over_rho\n",
    "\n",
    "    print(\"  [Prop2] best val eps-loss:\", best_prop2_loss,\n",
    "          \"| best rho =\", best_prop2_rho,\n",
    "          \"| best eps/rho =\", best_prop2_epsrho)\n",
    "\n",
    "    # ============================================================\n",
    "    # 9. Final retraining on Train+Val → TEST evaluation\n",
    "    # ============================================================\n",
    "\n",
    "    # ---------- SAA ----------\n",
    "    w_saa_final, _ = solve_empirical_svr_noreg(\n",
    "        X_trainval, y_trainval, epsilon=epsilon\n",
    "    )\n",
    "    test_loss_saa = eps_ins_loss(\n",
    "        y_test, X_test @ w_saa_final, epsilon\n",
    "    ).mean()\n",
    "\n",
    "    # ---------- W-SAA ----------\n",
    "    time_idx_month_tv = np.arange(len(np.unique(time_sorted[trainval_mask].astype(int))))\n",
    "    pi_time_wsaa_tv = time_weights_from_indices(\n",
    "        time_idx_month_tv,\n",
    "        now_t=len(time_idx_month_tv) - 1,\n",
    "        decay=best_wsaa_decay\n",
    "    )\n",
    "\n",
    "    time_trainval = time_sorted[trainval_mask].astype(int)\n",
    "    unique_tv, inv_idx_tv = np.unique(time_trainval, return_inverse=True)\n",
    "    counts_tv = np.bincount(inv_idx_tv)\n",
    "\n",
    "    pi_wsaa_samples_tv = pi_time_wsaa_tv[inv_idx_tv] / counts_tv[inv_idx_tv]\n",
    "    pi_wsaa_samples_tv = pi_wsaa_samples_tv / pi_wsaa_samples_tv.sum()\n",
    "\n",
    "    w_wsaa_final, _ = solve_empirical_svr_noreg(\n",
    "        X_trainval, y_trainval,\n",
    "        epsilon=epsilon,\n",
    "        sample_weights=pi_wsaa_samples_tv\n",
    "    )\n",
    "    test_loss_wsaa = eps_ins_loss(\n",
    "        y_test, X_test @ w_wsaa_final, epsilon\n",
    "    ).mean()\n",
    "\n",
    "    # ---------- WDRO ----------\n",
    "    pi_time_wdro_tv = time_weights_from_indices(\n",
    "        time_idx_month_tv,\n",
    "        now_t=len(time_idx_month_tv) - 1,\n",
    "        decay=best_wdro_decay\n",
    "    )\n",
    "\n",
    "    pi_wdro_samples_tv = pi_time_wdro_tv[inv_idx_tv] / counts_tv[inv_idx_tv]\n",
    "    pi_wdro_samples_tv = pi_wdro_samples_tv / pi_wdro_samples_tv.sum()\n",
    "\n",
    "    w_wdro_final, _ = solve_dro_svr_cor33(\n",
    "        X_trainval, y_trainval,\n",
    "        C1, c2, d,\n",
    "        pi_wdro_samples_tv,\n",
    "        epsilon=epsilon,\n",
    "        rho=best_wdro_rho\n",
    "    )\n",
    "    test_loss_wdro = eps_ins_loss(\n",
    "        y_test, X_test @ w_wdro_final, epsilon\n",
    "    ).mean()\n",
    "\n",
    "    # ---------- Prop2 ----------\n",
    "    pi_time_prop2_tv = optimal_weights_prop2(\n",
    "        len(time_idx_month_tv),\n",
    "        best_prop2_epsrho\n",
    "    )\n",
    "    pi_time_prop2_tv = pi_time_prop2_tv / pi_time_prop2_tv.sum()\n",
    "\n",
    "    pi_prop2_samples_tv = pi_time_prop2_tv[inv_idx_tv] / counts_tv[inv_idx_tv]\n",
    "    pi_prop2_samples_tv = pi_prop2_samples_tv / pi_prop2_samples_tv.sum()\n",
    "\n",
    "    w_prop2_final, _ = solve_dro_svr_cor33(\n",
    "        X_trainval, y_trainval,\n",
    "        C1, c2, d,\n",
    "        pi_prop2_samples_tv,\n",
    "        epsilon=epsilon,\n",
    "        rho=best_prop2_rho\n",
    "    )\n",
    "    test_loss_prop2 = eps_ins_loss(\n",
    "        y_test, X_test @ w_prop2_final, epsilon\n",
    "    ).mean()\n",
    "\n",
    "    print(\">> [SAA]   test eps-loss:\", test_loss_saa)\n",
    "    print(\">> [W-SAA] test eps-loss:\", test_loss_wsaa)\n",
    "    print(\">> [WDRO]  test eps-loss:\", test_loss_wdro)\n",
    "    print(\">> [Prop2] test eps-loss:\", test_loss_prop2)\n",
    "\n",
    "    # ------------------------------------------------\n",
    "    # 10. Store results\n",
    "    # ------------------------------------------------\n",
    "    results[\"ratio\"].append(ratio)\n",
    "    results[\"SAA\"].append(test_loss_saa)\n",
    "    results[\"W-SAA\"].append(test_loss_wsaa)\n",
    "    results[\"WDRO\"].append(test_loss_wdro)\n",
    "    results[\"Prop2\"].append(test_loss_prop2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98300e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratios = np.array(results[\"ratio\"])\n",
    "\n",
    "plt.figure(figsize=(7, 5))\n",
    "\n",
    "plt.plot(ratios, results[\"SAA\"],   marker=\"o\", label=\"SAA\")\n",
    "plt.plot(ratios, results[\"W-SAA\"], marker=\"s\", label=\"W-SAA\")\n",
    "plt.plot(ratios, results[\"WDRO\"],  marker=\"^\", label=\"WDRO\")\n",
    "plt.plot(ratios, results[\"Prop2\"], marker=\"x\", label=\"Prop2\")\n",
    "\n",
    "plt.xlabel(\"Training Time Ratio\")\n",
    "plt.ylabel(\"Test ε-Loss (NTD × 10⁴ / m²)\")\n",
    "plt.title(\"Test ε-Loss vs Training Horizon under Distribution Shift\")\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle=\":\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "convex",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
